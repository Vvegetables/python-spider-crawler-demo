#coding=utf-8
import queue
import requests

from education_crawler.utils.self_excel import excel_read


class SelfProcess:
    def __init__(self,_start_url,deep = 1,path = None,timeout=5):
        self.url = ((u for u in excel_read(path)) if path else None) or _start_url
        self.deep = deep
        self.data_q = queue.Queue()
        self.url_q = queue.Queue()
        self.spided_urls = None
        
    def spider(self):
        if not isinstance(self.url,list):
            self.url = [self.url]
        for _url in self.url:
            self.url_q.put(_url)
            deep = 0
            while not self.url_q.empty() and deep < self.deep:
                c_url = self.url_q.get()
                if c_url in self.spided_urls:
                    continue
    
    def handle_url(self,url,method='GET',timeout=5,*args,**kwargs):
        r = {
            'GET': requests.get,
            'POST': requests.post,
        }
        try:
            response = r.get(method)(url, timeout=timeout, *args, **kwargs)
            if 'Connection' in response.headers.keys():
                del response.headers['Connection']
            except socket.timeout:
                print 'timeout'
                response = self.err_response()
        